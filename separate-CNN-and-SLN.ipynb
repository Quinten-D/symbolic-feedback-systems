{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484dd0e9-f9d0-49d5-aeed-51767aaecd73",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e59a5-bda7-46c6-89f4-696d23e41805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import tqdm # version 4.40.0\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from cpmpy import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3cd03e-cad2-44cd-9f11-326cef1a07af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Make/load the sudoku boards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5adff2a-e331-4b7c-98d4-898e657fe4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Make fixed sudoku boards for training and testing -----\n",
    "# train sudoku boards consist of train MNIST images, test sudoku boards of test MNIST images\n",
    "\n",
    "# Sudoku boards\n",
    "# from https://github.com/locuslab/SATNet/blob/master/exps/sudoku.py\n",
    "datadir = \"sudoku\"\n",
    "with open(os.path.join(datadir,'features.pt'), 'rb') as f:\n",
    "    X_in = torch.load(f)\n",
    "with open(os.path.join(datadir,'labels.pt'), 'rb') as f:\n",
    "    Y_in = torch.load(f)\n",
    "\n",
    "# Divide the boards (2000 test, 8000 train)\n",
    "train_ids = [i for i in range(0, 7000)]\n",
    "validation_ids = [i for i in range(7000, 8000)]\n",
    "test_ids = [i for i in range(8000, 10000)]\n",
    "\n",
    "# Normalize MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the MNIST data\n",
    "testset = datasets.MNIST('.', download=True, train=False, transform=transform)\n",
    "digit_indices_test = {k:torch.LongTensor(*np.where(testset.targets == k)) for k in range(0,10)}\n",
    "trainset = datasets.MNIST('.', download=True, train=True, transform=transform)\n",
    "\n",
    "# Make validation set\n",
    "# Initialize counters for each digit class in the validation set\n",
    "count_per_class = [0] * 10\n",
    "# Initialize arrays for the validation set\n",
    "validation_set = []\n",
    "train_set = []\n",
    "# Iterate through the training set and move samples to the validation set\n",
    "for img, label in trainset:\n",
    "    if count_per_class[label] < 1000:\n",
    "        validation_set.append([img, label])\n",
    "        count_per_class[label] += 1\n",
    "    else:\n",
    "        train_set.append([img, label])\n",
    "validation_labels = np.array([x[1] for x in validation_set])\n",
    "digit_indices_validation = {k:torch.LongTensor(*np.where(validation_labels == k)) for k in range(0,10)}\n",
    "train_labels = np.array([x[1] for x in train_set])\n",
    "digit_indices_train = {k:torch.LongTensor(*np.where(train_labels == k)) for k in range(0,10)}\n",
    "\n",
    "\n",
    "# Define constants\n",
    "N_CHANNEL = 1 # MNIST images are in grey scale \n",
    "IMAGE_WIDTH = 28 # MNIST image width\n",
    "IMAGE_HEIGHT = 28 # MNIST image height\n",
    "\n",
    "\n",
    "# fix the seed for board generation\n",
    "torch.manual_seed(9168)\n",
    "np.random.seed(9168)\n",
    "rng = np.random.RandomState(243)\n",
    "\n",
    "\n",
    "def sample_visual_sudoku_test(sudoku_puzzle):\n",
    "    \"\"\"\n",
    "        Turn the given `sudoku_puzzle` into a visual puzzle by replace numeric values\n",
    "        by images from MNIST. \n",
    "    \"\"\"\n",
    "    # Visual Sudoku Tensor of shape puzzle_width x puzzle_height x n_channel x image_width x image_height\n",
    "    sudoku_torch_dimension = sudoku_puzzle.shape + (N_CHANNEL, IMAGE_WIDTH, IMAGE_HEIGHT,)\n",
    "    vizsudoku = torch.zeros(sudoku_torch_dimension, dtype=torch.float32)\n",
    "\n",
    "    # sample dataset indices for each non-zero digit\n",
    "    #for val in np.unique(sudoku_puzzle[sudoku_puzzle > 0]):\n",
    "    for val in np.unique(sudoku_puzzle):\n",
    "        val_idx = np.where(sudoku_puzzle == val)\n",
    "        # randomly sample different MNIST images for a given digit all at once\n",
    "        idx = torch.LongTensor(rng.choice(digit_indices_test[val], len(sudoku_puzzle[val_idx])))\n",
    "        vizsudoku[val_idx] = torch.stack([testset[i][0] for i in idx])\n",
    "        #print(val, idx)\n",
    "    return vizsudoku\n",
    "\n",
    "\n",
    "def sample_visual_sudoku_test_correlated(sudoku_puzzle):\n",
    "    \"\"\"\n",
    "        Turn the given `sudoku_puzzle` into a visual puzzle by replace numeric values\n",
    "        by images from MNIST. \n",
    "    \"\"\"\n",
    "    # Visual Sudoku Tensor of shape puzzle_width x puzzle_height x n_channel x image_width x image_height\n",
    "    sudoku_torch_dimension = sudoku_puzzle.shape + (N_CHANNEL, IMAGE_WIDTH, IMAGE_HEIGHT,)\n",
    "    vizsudoku = torch.zeros(sudoku_torch_dimension, dtype=torch.float32)\n",
    "\n",
    "    # sample dataset indices for each non-zero digit\n",
    "    #for val in np.unique(sudoku_puzzle[sudoku_puzzle > 0]):\n",
    "    for val in np.unique(sudoku_puzzle):\n",
    "        val_idx = np.where(sudoku_puzzle == val)\n",
    "        # randomly sample different MNIST images for a given digit all at once\n",
    "        idx = torch.LongTensor(rng.choice(digit_indices_test[val], len(sudoku_puzzle[val_idx])))\n",
    "        # Add noise\n",
    "        images_with_noise = [add_noise(testset[idx[0]][0], noise_level=0.75) for i in idx]\n",
    "        vizsudoku[val_idx] = torch.stack([torch.tensor(img) for img in images_with_noise])\n",
    "    return vizsudoku\n",
    "\n",
    "\n",
    "def sample_visual_sudoku_train(sudoku_puzzle):\n",
    "    \"\"\"\n",
    "        Turn the given `sudoku_puzzle` into a visual puzzle by replace numeric values\n",
    "        by images from MNIST. \n",
    "    \"\"\"\n",
    "    # Visual Sudoku Tensor of shape puzzle_width x puzzle_height x n_channel x image_width x image_height\n",
    "    sudoku_torch_dimension = sudoku_puzzle.shape + (N_CHANNEL, IMAGE_WIDTH, IMAGE_HEIGHT,)\n",
    "    vizsudoku = torch.zeros(sudoku_torch_dimension, dtype=torch.float32)\n",
    "\n",
    "    # sample dataset indices for each non-zero digit\n",
    "    #for val in np.unique(sudoku_puzzle[sudoku_puzzle > 0]):\n",
    "    for val in np.unique(sudoku_puzzle):\n",
    "        val_idx = np.where(sudoku_puzzle == val)\n",
    "        # randomly sample different MNIST images for a given digit all at once\n",
    "        idx = torch.LongTensor(rng.choice(digit_indices_train[val], len(sudoku_puzzle[val_idx])))\n",
    "        vizsudoku[val_idx] = torch.stack([train_set[i][0] for i in idx])\n",
    "        #print(val, idx)\n",
    "    return vizsudoku\n",
    "\n",
    "\n",
    "def sample_visual_sudoku_validation(sudoku_puzzle):\n",
    "    \"\"\"\n",
    "        Turn the given `sudoku_puzzle` into a visual puzzle by replace numeric values\n",
    "        by images from MNIST. \n",
    "    \"\"\"\n",
    "    # Visual Sudoku Tensor of shape puzzle_width x puzzle_height x n_channel x image_width x image_height\n",
    "    sudoku_torch_dimension = sudoku_puzzle.shape + (N_CHANNEL, IMAGE_WIDTH, IMAGE_HEIGHT,)\n",
    "    vizsudoku = torch.zeros(sudoku_torch_dimension, dtype=torch.float32)\n",
    "\n",
    "    # sample dataset indices for each non-zero digit\n",
    "    #for val in np.unique(sudoku_puzzle[sudoku_puzzle > 0]):\n",
    "    for val in np.unique(sudoku_puzzle):\n",
    "        val_idx = np.where(sudoku_puzzle == val)\n",
    "        # randomly sample different MNIST images for a given digit all at once\n",
    "        idx = torch.LongTensor(rng.choice(digit_indices_validation[val], len(sudoku_puzzle[val_idx])))\n",
    "        vizsudoku[val_idx] = torch.stack([validation_set[i][0] for i in idx])\n",
    "        #print(val, idx)\n",
    "    return vizsudoku\n",
    "\n",
    "\n",
    "def sample_visual_sudoku_validation_correlated(sudoku_puzzle):\n",
    "    \"\"\"\n",
    "        Turn the given `sudoku_puzzle` into a visual puzzle by replace numeric values\n",
    "        by images from MNIST. \n",
    "    \"\"\"\n",
    "    # Visual Sudoku Tensor of shape puzzle_width x puzzle_height x n_channel x image_width x image_height\n",
    "    sudoku_torch_dimension = sudoku_puzzle.shape + (N_CHANNEL, IMAGE_WIDTH, IMAGE_HEIGHT,)\n",
    "    vizsudoku = torch.zeros(sudoku_torch_dimension, dtype=torch.float32)\n",
    "\n",
    "    # sample dataset indices for each non-zero digit\n",
    "    #for val in np.unique(sudoku_puzzle[sudoku_puzzle > 0]):\n",
    "    for val in np.unique(sudoku_puzzle):\n",
    "        val_idx = np.where(sudoku_puzzle == val)\n",
    "        # randomly sample different MNIST images for a given digit all at once\n",
    "        idx = torch.LongTensor(rng.choice(digit_indices_validation[val], len(sudoku_puzzle[val_idx])))\n",
    "        # Add noise\n",
    "        images_with_noise = [add_noise(validation_set[idx[0]][0], noise_level=0.75) for i in idx]\n",
    "        vizsudoku[val_idx] = torch.stack([torch.tensor(img) for img in images_with_noise])\n",
    "    return vizsudoku\n",
    "\n",
    "\n",
    "# Define a function to add random noise to an image\n",
    "def add_noise(image, noise_level=0.1):\n",
    "    noise = np.random.normal(scale=noise_level, size=image.shape)\n",
    "    noisy_image = image + noise\n",
    "    return torch.tensor(noisy_image.clip(-1, 1), dtype=torch.float32).clone().detach()  # Ensure values are within [-1, 1] range\n",
    "\n",
    "\n",
    "def transform_labels(sudoku):\n",
    "    new_labels = torch.zeros(9, 9)\n",
    "    tensor_digits = torch.arange(1, 10)\n",
    "    for i in range(0, 9):\n",
    "        for j in range(0, 9):\n",
    "            digit_vector = sudoku[i, j]\n",
    "            new_labels[i, j] = torch.sum(tensor_digits * digit_vector)\n",
    "    return new_labels.numpy().astype(int)\n",
    "\n",
    "\n",
    "# ----- Do the test sudokus -----\n",
    "visual_test_sudokus = []\n",
    "numerical_test_sudokus = []\n",
    "completed_numerical_test_sudokus = []\n",
    "\n",
    "for i in test_ids:\n",
    "    completed_numerical_sudoku = torch.from_numpy(transform_labels(Y_in[i]))\n",
    "    numerical_sudoku = torch.from_numpy(transform_labels(X_in[i]))\n",
    "    visual_sudoku = sample_visual_sudoku_test(transform_labels(X_in[i]))\n",
    "    visual_test_sudokus.append(visual_sudoku)\n",
    "    numerical_test_sudokus.append(numerical_sudoku)\n",
    "    completed_numerical_test_sudokus.append(completed_numerical_sudoku)\n",
    " \n",
    "# torch.save(visual_test_sudokus, 'visual_test_sudokus.pth')\n",
    "# torch.save(numerical_test_sudokus, 'numerical_test_sudokus.pth')\n",
    "# torch.save(completed_numerical_test_sudokus, 'completed_numerical_test_sudokus.pth')\n",
    "\n",
    "\n",
    "# ----- Do the correlated test sudokus -----\n",
    "visual_correlated_test_sudokus = []\n",
    "\n",
    "for i in test_ids:\n",
    "    completed_numerical_sudoku = torch.from_numpy(transform_labels(Y_in[i]))\n",
    "    numerical_sudoku = torch.from_numpy(transform_labels(X_in[i]))\n",
    "    visual_sudoku = sample_visual_sudoku_test_correlated(transform_labels(X_in[i]))\n",
    "    visual_correlated_test_sudokus.append(visual_sudoku)\n",
    " \n",
    " \n",
    "# ----- Do the train sudokus -----\n",
    "visual_train_sudokus = []\n",
    "numerical_train_sudokus = []\n",
    "completed_numerical_train_sudokus = []\n",
    "\n",
    "for i in train_ids:\n",
    "    completed_numerical_sudoku = torch.from_numpy(transform_labels(Y_in[i]))\n",
    "    numerical_sudoku = torch.from_numpy(transform_labels(X_in[i]))\n",
    "    visual_sudoku = sample_visual_sudoku_train(transform_labels(X_in[i]))\n",
    "    visual_train_sudokus.append(visual_sudoku)\n",
    "    numerical_train_sudokus.append(numerical_sudoku)\n",
    "    completed_numerical_train_sudokus.append(completed_numerical_sudoku)\n",
    "\n",
    "# torch.save(visual_train_sudokus, 'visual_train_sudokus.pth')\n",
    "# torch.save(numerical_train_sudokus, 'numerical_train_sudokus.pth')\n",
    "# torch.save(completed_numerical_train_sudokus, 'completed_numerical_train_sudokus.pth')\n",
    "\n",
    "\n",
    "# ----- Do the validation sudokus -----\n",
    "visual_validation_sudokus = []\n",
    "numerical_validation_sudokus = []\n",
    "completed_numerical_validation_sudokus = []\n",
    "\n",
    "for i in validation_ids:\n",
    "    completed_numerical_sudoku = torch.from_numpy(transform_labels(Y_in[i]))\n",
    "    numerical_sudoku = torch.from_numpy(transform_labels(X_in[i]))\n",
    "    visual_sudoku = sample_visual_sudoku_validation(transform_labels(X_in[i]))\n",
    "    visual_validation_sudokus.append(visual_sudoku)\n",
    "    numerical_validation_sudokus.append(numerical_sudoku)\n",
    "    completed_numerical_validation_sudokus.append(completed_numerical_sudoku)\n",
    "\n",
    "# torch.save(visual_validation_sudokus, 'visual_validation_sudokus.pth')\n",
    "# torch.save(numerical_validation_sudokus, 'numerical_validation_sudokus.pth')\n",
    "# torch.save(completed_numerical_validation_sudokus, 'completed_numerical_validation_sudokus.pth')\n",
    "\n",
    "\n",
    "# ----- Do the correlated validation sudokus -----\n",
    "visual_correlated_validation_sudokus = []\n",
    "\n",
    "for i in validation_ids:\n",
    "    completed_numerical_sudoku = torch.from_numpy(transform_labels(Y_in[i]))\n",
    "    numerical_sudoku = torch.from_numpy(transform_labels(X_in[i]))\n",
    "    visual_sudoku = sample_visual_sudoku_validation_correlated(transform_labels(X_in[i]))\n",
    "    visual_correlated_validation_sudokus.append(visual_sudoku)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ad1f7-852d-4b34-a9dc-993737f76452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also define a helper function to visualize the visual puzzle\n",
    "\n",
    "N_CHANNEL = 1 # MNIST images are in grey scale \n",
    "IMAGE_WIDTH = 28 # MNIST image width\n",
    "IMAGE_HEIGHT = 28 # MNIST image height\n",
    "\n",
    "def show_grid_img(visual_sudoku, in_green=None, in_red=None, title=None):\n",
    "    images =visual_sudoku.reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    images = (255 * images).int()\n",
    "    dim = visual_sudoku.shape[0]\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=(dim,dim), axes_pad=0.03)\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    # cells to plot in green | red\n",
    "    N = len(images)\n",
    "    if in_green is None:\n",
    "        in_green = np.zeros(N, dtype=bool)\n",
    "    if in_red is None:\n",
    "        in_red = np.zeros(N, dtype=bool)\n",
    "    in_green = in_green.flatten()\n",
    "    in_red = in_red.flatten()\n",
    "    \n",
    "    for ax, index in zip(grid, range(len(images))):\n",
    "        # dont display ticks\n",
    "        for axis in ax.axis.values():\n",
    "            axis.toggle(ticks=False, ticklabels=False)\n",
    "        # color appropriately\n",
    "        color = 'gray_r'\n",
    "        if in_red[index]:\n",
    "            color = 'autumn'\n",
    "        if in_green[index]:\n",
    "            color = 'summer'\n",
    "        # and show\n",
    "        ax.imshow(images[index].numpy().squeeze(), cmap=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c452581-8204-48d2-be4a-2a505f58bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some puzzles\n",
    "show_grid_img(visual_validation_sudokus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8818cb-de5f-4c0b-8a28-0083eba5a620",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train CNN & SLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea0699-d237-48ce-aac0-28a57ca46c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convolutional Neural Network for digit classification\n",
    "\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, 1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 5*5*16) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        #return F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def forward2(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 5*5*16) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = self.fc2(x)\n",
    "        #x = self.fc3(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        #return F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TinyLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyLeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, 5, 1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(1, 2, 5, 1)\n",
    "        self.fc1 = nn.Linear(5*5*2, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 5*5*2) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class SmallLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallLeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 5, 1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(2, 3, 5, 1)\n",
    "        self.fc1 = nn.Linear(5*5*3, 30)\n",
    "        self.fc2 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 5*5*3) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def load_classifier(clf_classname, path):\n",
    "    \"\"\"\n",
    "        Initialize a new CNN classifier by\n",
    "        loading pre-trained weights stored in `path` file\n",
    "    \"\"\"\n",
    "    net = clf_classname()\n",
    "    state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "    net.load_state_dict(state_dict)\n",
    "    return net\n",
    "\n",
    "def load_classifier2(clf_classname, path):\n",
    "    \"\"\"\n",
    "        Initialize a new CNN classifier by\n",
    "        loading pre-trained weights stored in `path` file\n",
    "    \"\"\"\n",
    "    net = clf_classname()\n",
    "    net_state_dict = net.state_dict()\n",
    "    state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "    state_dict = {k: v for k, v in state_dict.items() if k in net_state_dict}\n",
    "    net_state_dict.update(state_dict)\n",
    "    net.load_state_dict(net_state_dict)\n",
    "\n",
    "    # Freeze loaded weights\n",
    "    for name, param in net.named_parameters():\n",
    "        if name in state_dict:\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            param.requires_grad = True\n",
    "    return net\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_proba_sudoku_2(neuralnet, vizsudoku):\n",
    "    \"\"\"\n",
    "        Assign a probabilistic vector to each image of the visual puzzle\n",
    "    \"\"\"\n",
    "    grid_shape = vizsudoku.shape[:2]\n",
    "    # reshape from 9x9x1x28x28 to 81x1x28x28 \n",
    "    pred = neuralnet(vizsudoku.flatten(0,1))\n",
    "    partial_evidence_vectors = torch.ones((81, 10))\n",
    "    complete_inputs = torch.cat((pred, partial_evidence_vectors), dim=1)\n",
    "    outputs = refinement_net(complete_inputs)\n",
    "    outputs = F.softmax(outputs, dim=1)\n",
    "    outputs = outputs.cpu()  # Move the tensor to the CPU\n",
    "    # our NN return 81 probabilistic vector: an 81x10 matrix\n",
    "    return outputs.reshape(*grid_shape,10).detach().numpy() # reshape as 9x9x10 tensor for easier visualisation\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_proba_sudoku(neuralnet, vizsudoku):\n",
    "    \"\"\"\n",
    "        Assign a probabilistic vector to each image of the visual puzzle\n",
    "    \"\"\"\n",
    "    grid_shape = vizsudoku.shape[:2]\n",
    "    # reshape from 9x9x1x28x28 to 81x1x28x28 \n",
    "    pred = neuralnet(vizsudoku.flatten(0,1))\n",
    "    pred = F.softmax(pred, dim=1)\n",
    "    pred = pred.cpu()  # Move the tensor to the CPU\n",
    "    # our NN return 81 probabilistic vector: an 81x10 matrix\n",
    "    return pred.reshape(*grid_shape,10).detach().numpy() # reshape as 9x9x10 tensor for easier visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a19e28-8f2a-4ea6-94ba-1e2429a15c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "\n",
    "\n",
    "# Set the seed for NumPy's random number generator\n",
    "np.random.seed(1232)\n",
    "\n",
    "\n",
    "class CustomCNNDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.data[idx][1]\n",
    "        img = self.data[idx][0]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf716a-bb7e-4784-84af-955cdad404dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "\n",
    "# Seed CNN\n",
    "torch.manual_seed(422)  # 4287, 9623, 5896, 42, 596, 6343439\n",
    "np.random.seed(422)\n",
    "\n",
    "\n",
    "# Make dataloaders\n",
    "cnn_trainset = CustomCNNDataset(train_set)\n",
    "cnn_testset = CustomCNNDataset(validation_set)\n",
    "cnn_train_loader = DataLoader(cnn_trainset, batch_size=64, shuffle=True)\n",
    "cnn_test_loader = DataLoader(cnn_testset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Initialize the neural network and define the loss function and optimizer\n",
    "cnn = SmallLeNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    cnn.train()\n",
    "    for i, data in enumerate(cnn_train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(cnn_train_loader)}], Loss: {running_loss/100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Print test loss\n",
    "            cnn.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            running_test_loss = 0.0\n",
    "            batches = 0\n",
    "            with torch.no_grad():\n",
    "                for data in cnn_test_loader:\n",
    "                    inputs, labels = data\n",
    "                    outputs = cnn(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    running_test_loss += loss.item()\n",
    "                    batches += 1\n",
    "        \n",
    "            accuracy = 100 * correct / total\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] - Test Accuracy: {accuracy:.2f}% - Test Loss: {running_test_loss/batches:.4f}')\n",
    "\n",
    "    \n",
    "print('Training finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc82a5a-4d31-4cfc-91aa-41c7c97e87e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print test accuracy\n",
    "\n",
    "# Manual loading\n",
    "#cnn = SmallLeNet()\n",
    "#cnn.load_state_dict(torch.load('SmallLeNet_0.960.pth'))\n",
    "# cnn = trained_sln\n",
    "\n",
    "torch.manual_seed(9168)\n",
    "np.random.seed(9168)\n",
    "\n",
    "cnn_testset = CustomCNNDataset(testset)\n",
    "cnn_test_loader = DataLoader(cnn_testset, batch_size=64, shuffle=False)\n",
    "\n",
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "running_test_loss = 0.0\n",
    "batches = 0\n",
    "with torch.no_grad():\n",
    "    for data in cnn_test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_test_loss += loss.item()\n",
    "        batches += 1\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}% - Test Loss: {running_test_loss/batches:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640175d-22a2-484f-b26b-702b713ca4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual saving\n",
    "\n",
    "torch.save(cnn.state_dict(), 'SmallLeNet_0.9.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dbe3e0-1434-4dda-b42c-b47f81e42f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual loading\n",
    "\n",
    "cnn = LeNet()\n",
    "cnn.load_state_dict(torch.load('LeNet_0.944.pth'))\n",
    "cnn.eval()\n",
    "\n",
    "# Count the number of weights\n",
    "num_weights = sum(p.numel() for p in cnn.parameters() if p.requires_grad)\n",
    "print(\"Number of weights in the model:\", num_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5091e9-d086-4d44-8500-4cccfdf5b903",
   "metadata": {},
   "source": [
    "# Sudoku solving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84aef19-f64c-4ec0-9360-15099f11ce1a",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037487c-85e4-4c89-bbe2-e07e67fd099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Own model\n",
    "\n",
    "import cpmpy as cp\n",
    "from cpmpy.solvers import CPM_ortools\n",
    "\n",
    "\n",
    "def get_sudoku_model(n=9):\n",
    "    b = np.sqrt(n).astype(int)\n",
    "    cells = cp.IntVar(1, n, shape=(n,n))\n",
    "\n",
    "    # plain sudoku model\n",
    "    m = cp.Model(\n",
    "        [cp.alldifferent(row) for row in cells],\n",
    "        [cp.alldifferent(col) for col in cells.T],\n",
    "        [cp.alldifferent(cells[i:i + b, j:j + b])\n",
    "            for i in range(0, n, b) for j in range(0, n, b)],\n",
    "    )\n",
    "    return {\n",
    "        'model':m,\n",
    "        'variables':cells\n",
    "    }\n",
    "\n",
    "\n",
    "def solve_sudoku(model, dvars, instance):\n",
    "    # use another object for solving\n",
    "    newmodel = cp.Model(model.constraints) \n",
    "    # set given clues\n",
    "    newmodel += cp.all(instance[instance>0] == dvars[instance>0])\n",
    "    if newmodel.solve():\n",
    "        results = {\n",
    "            'runtime':np.asarray(newmodel.cpm_status.runtime),\n",
    "            'solution':dvars.value(),\n",
    "        }\n",
    "    else:\n",
    "        results = {\n",
    "            'solution':np.full_like(dvars.value(), np.nan)\n",
    "        }\n",
    "    results['status'] = np.asarray(newmodel.cpm_status.exitstatus.value)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_visual_sudoku_full_image_model(ml_predictions, precision=1e-5):\n",
    "    # base model and decision variables \n",
    "    visual_sudoku_problem = get_sudoku_model()\n",
    "    model = visual_sudoku_problem['model']\n",
    "    decision_variables = visual_sudoku_problem['variables']\n",
    "    # introduce a layer of 'perception' variables, as an interface\n",
    "    # between the solver and the ml network\n",
    "    # their domain is [0, ..., 9], with 0 acting as the 'empty' symbol\n",
    "    perception_variables = cp.intvar(0, 9, shape=decision_variables.shape, name='perception')\n",
    "\n",
    "    # convert predictions to logspace\n",
    "    logprobs = np.log(np.maximum( ml_predictions, precision ))\n",
    "    # cp solver requires integer values\n",
    "    logprobs = np.array(logprobs / precision).astype(int)\n",
    "    # switch to cpm_array for more features\n",
    "    logprobs = cp.cpm_array(logprobs)\n",
    "    # build the objective function over perception variables \n",
    "    objective_function = sum(logprobs[idx][v] for idx,v in np.ndenumerate(perception_variables))\n",
    "    model.maximize(objective_function)\n",
    "    \n",
    "    # channeling constraints to link decision variables to perception variables\n",
    "    # perception variable is either 'empty' or matches grid symbol\n",
    "    model+= [(perception_variables != 0).implies(decision_variables == perception_variables)]\n",
    "    # keep track of perception variables as well \n",
    "    visual_sudoku_problem['perception'] = perception_variables\n",
    "    return visual_sudoku_problem\n",
    "\n",
    "def solve_visual_sudoku_full_image(visual_sudoku_problem, solver_params=dict()):\n",
    "    model = visual_sudoku_problem['model']\n",
    "    dvars, pvars = visual_sudoku_problem['variables'], visual_sudoku_problem['perception']\n",
    "    s = CPM_ortools(model)\n",
    "    if s.solve(**solver_params):\n",
    "        results = {\n",
    "            'solution':dvars.value(),\n",
    "            'perception':pvars.value()\n",
    "        }\n",
    "    else:\n",
    "        # in case of infeasibility, nan\n",
    "        results = {\n",
    "            'solution':np.full_like(dvars.value(), np.nan),\n",
    "            'perception':np.full_like(dvars.value(), np.nan)\n",
    "        }\n",
    "    results['status'] = np.asarray(s.cpm_status.exitstatus.value)\n",
    "    results['runtime'] = np.asarray(s.cpm_status.runtime)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd48e01-d16a-4965-91b6-fec3680c354c",
   "metadata": {},
   "source": [
    "## Maximum Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7000140-f6a2-443b-af95-fbc5d2c813a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perception_leads_to_unique_solution(perception, solution):\n",
    "    sudoku_mod = get_sudoku_model(n=9)\n",
    "    vars = sudoku_mod[\"variables\"]\n",
    "    model = sudoku_mod[\"model\"]\n",
    "    model += ~ cp.all((vars == solution).flatten())\n",
    "    is_unique = not solve_sudoku_again(model, vars, perception)\n",
    "    return is_unique\n",
    "\n",
    "\n",
    "def solve_sudoku_again(model, dvars, instance):\n",
    "    # use another object for solving\n",
    "    newmodel = cp.Model(model.constraints) \n",
    "    # set given clues\n",
    "    newmodel += cp.all(instance[instance>0] == dvars[instance>0])\n",
    "    return newmodel.solve()\n",
    "\n",
    "\n",
    "def solve_visual_sudoku_higher_order(visual_sudoku_problem, solver_params=dict(), max_iter=10):\n",
    "    #Write a loop repeating following steps:\n",
    "    # while results['solution'] is not unique or iteration < max_iter:\n",
    "    #   add nogood to the vizsudoku model\n",
    "    #   solve again\n",
    "    #   iteration += 1\n",
    "    \n",
    "    model = visual_sudoku_problem['model']\n",
    "    dvars, pvars = visual_sudoku_problem['variables'], visual_sudoku_problem['perception']\n",
    "    results = solve_visual_sudoku_full_image(visual_sudoku_problem, solver_params)\n",
    "    #print(\"first \", results)\n",
    "    iteration = 0\n",
    "    \n",
    "    while (not perception_leads_to_unique_solution(pvars.value(), dvars.value())) and (iteration < max_iter):\n",
    "      # add nogood to the vizsudoku model\n",
    "      #model += [~cp.all((perception_variables ==  perception_variables.value())) ]\n",
    "      model += ~ cp.all((pvars == results['perception']).flatten())\n",
    "      results = solve_visual_sudoku_full_image(visual_sudoku_problem, solver_params)\n",
    "      iteration += 1\n",
    "    if iteration >= max_iter:\n",
    "        print(\"max iter exceeded at solving for unique solution\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b42347-4eea-4b61-9b1e-5e27911ebe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_unique_solution(visual_sudoku, cnn):\n",
    "    # convolutional neural network predictions \n",
    "    ml_predictions = predict_proba_sudoku(cnn, visual_sudoku)\n",
    "    \n",
    "    # visual sudoku cp model\n",
    "    visual_sudoku_problem = get_visual_sudoku_full_image_model(ml_predictions)\n",
    "    \n",
    "    # solve \n",
    "    #results = solve_visual_sudoku_full_image(visual_sudoku_problem)\n",
    "    results = solve_visual_sudoku_higher_order(visual_sudoku_problem)\n",
    "    return results\n",
    "\n",
    "\n",
    "def top_k_inference_unique_solution(visual_sudoku, cnn, k=1):\n",
    "    return_list = []\n",
    "    # convolutional neural network predictions \n",
    "    ml_predictions = predict_proba_sudoku(cnn, visual_sudoku)\n",
    "    # visual sudoku cp model\n",
    "    visual_sudoku_problem = get_visual_sudoku_full_image_model(ml_predictions)\n",
    "    model = visual_sudoku_problem['model']\n",
    "    dvars, pvars = visual_sudoku_problem['variables'], visual_sudoku_problem['perception']\n",
    "    for i in range(0, k):\n",
    "        results = solve_visual_sudoku_higher_order(visual_sudoku_problem)\n",
    "        return_list.append(results)\n",
    "        model += ~ cp.all((pvars == results['perception']).flatten())\n",
    "        #model += ~ cp.all((dvars == results['solution']).flatten()) # new addition\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d145682-a2bc-4598-b917-16a254a4bb14",
   "metadata": {},
   "source": [
    "## Symbolic feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c26a91-32bf-429b-a129-e789ba8e2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def find_index_of_element_in_arrays(arrays, t):\n",
    "    \"\"\"\n",
    "    Find the index of an element with value t across multiple NumPy arrays.\n",
    "\n",
    "    Parameters:\n",
    "        arrays (list of numpy.ndarray): List of NumPy arrays.\n",
    "        t (int or float): Value to find across the arrays.\n",
    "\n",
    "    Returns:\n",
    "        index (tuple or None): Index of the element in the arrays, or None if not found.\n",
    "    \"\"\"\n",
    "    # Check if all arrays have the same shape\n",
    "    shapes = [arr.shape for arr in arrays]\n",
    "    if len(set(shapes)) != 1:\n",
    "        raise ValueError(\"All arrays must have the same shape\")\n",
    "\n",
    "    # Stack arrays along a new axis\n",
    "    stacked_array = np.stack(arrays)\n",
    "\n",
    "    # Check if t exists in all arrays\n",
    "    presence = np.all(stacked_array == t, axis=0)\n",
    "\n",
    "    # If t is present in all arrays, find its index\n",
    "    if np.any(presence):\n",
    "        index = np.where(presence)\n",
    "        return (index[0][0], index[1][0])  # Return only the index of the first occurrence\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "\n",
    "def inference_with_feedback(visual_sudoku, cnn, sln, top_k_boards=5):\n",
    "    # convolutional neural network predictions \n",
    "    original_ml_predictions = predict_proba_sudoku(cnn, visual_sudoku)\n",
    "    ml_predictions = copy.deepcopy(original_ml_predictions)\n",
    "    \n",
    "    # call the solver\n",
    "    visual_sudoku_problem = get_visual_sudoku_full_image_model(ml_predictions)\n",
    "    model = visual_sudoku_problem['model']\n",
    "    dvars, pvars = visual_sudoku_problem['variables'], visual_sudoku_problem['perception']\n",
    "    board_list = []\n",
    "    complete_board_list = []\n",
    "    for i in range(0, top_k_boards):\n",
    "        results = solve_visual_sudoku_higher_order(visual_sudoku_problem)\n",
    "        board_list.append(results)\n",
    "        complete_board_list.append(results)\n",
    "        model += ~ cp.all((pvars == results['perception']).flatten())\n",
    "        #model += ~ cp.all((dvars == results['solution']).flatten()) # new addition\n",
    "    top_boards = [board[\"perception\"] for board in board_list]\n",
    "\n",
    "    # refine probabilities\n",
    "    for i in range(0, 9):\n",
    "        for j in range(0, 9):\n",
    "            initial_probabilities = ml_predictions[i, j]\n",
    "            partial_evidence = [board[i, j] for board in top_boards]\n",
    "            if (len(set(partial_evidence)) > 1) and (len(set(partial_evidence)) < 10):\n",
    "                # Construct complete input for the sln\n",
    "                complete_input = torch.zeros(1, 11, 1, 28, 28)\n",
    "                complete_input[0, 0] = visual_sudoku[i, j]\n",
    "                for k in range(0, 10):\n",
    "                    index = find_index_of_element_in_arrays(top_boards, k)\n",
    "                    if index is not None:\n",
    "                        complete_input[0, k+1] = visual_sudoku[index[0], index[1]]\n",
    "                with torch.no_grad():\n",
    "                    refined_probability = sln(complete_input)[0]\n",
    "                    refined_probability = torch.nn.functional.softmax(refined_probability, dim=0).numpy()\n",
    "                ml_predictions[i, j] = refined_probability\n",
    "\n",
    "    # Max top board\n",
    "    choice = 0\n",
    "    top_score = 0\n",
    "    new_scores = []\n",
    "    old_scores = []\n",
    "    for i, board in enumerate(top_boards):\n",
    "        score = 1\n",
    "        old_score = 1\n",
    "        for row in range(0,9):\n",
    "            for col in range(0,9):\n",
    "                score *= ml_predictions[row, col, board[row, col]]\n",
    "                old_score *= original_ml_predictions[row, col, board[row, col]]\n",
    "        new_scores.append(score)\n",
    "        old_scores.append(old_score)\n",
    "        if score > top_score:\n",
    "            top_score = score\n",
    "            choice = i \n",
    "    \n",
    "    return complete_board_list[choice]\n",
    "\n",
    "\n",
    "def inference_with_feedback_double_cnn(visual_sudoku, cnn, sln, top_k_boards=5):\n",
    "    # convolutional neural network predictions \n",
    "    original_ml_predictions = predict_proba_sudoku(cnn, visual_sudoku)\n",
    "    ml_predictions = copy.deepcopy(original_ml_predictions)\n",
    "    \n",
    "    # call the solver\n",
    "    visual_sudoku_problem = get_visual_sudoku_full_image_model(ml_predictions)\n",
    "    model = visual_sudoku_problem['model']\n",
    "    dvars, pvars = visual_sudoku_problem['variables'], visual_sudoku_problem['perception']\n",
    "    board_list = []\n",
    "    complete_board_list = []\n",
    "    for i in range(0, top_k_boards):\n",
    "        results = solve_visual_sudoku_higher_order(visual_sudoku_problem)\n",
    "        board_list.append(results)\n",
    "        complete_board_list.append(results)\n",
    "        model += ~ cp.all((pvars == results['perception']).flatten())\n",
    "        #model += ~ cp.all((dvars == results['solution']).flatten()) # new addition\n",
    "    top_boards = [board[\"perception\"] for board in board_list]\n",
    "\n",
    "    # refine probabilities\n",
    "    for i in range(0, 9):\n",
    "        for j in range(0, 9):\n",
    "            initial_probabilities = ml_predictions[i, j]\n",
    "            partial_evidence = [board[i, j] for board in top_boards]\n",
    "            if (len(set(partial_evidence)) > 1) and (len(set(partial_evidence)) < 10):\n",
    "                with torch.no_grad():\n",
    "                    refined_probability = sln(visual_sudoku[i, j])[0]\n",
    "                    refined_probability = torch.nn.functional.softmax(refined_probability, dim=0).numpy()\n",
    "                ml_predictions[i, j] = refined_probability\n",
    "\n",
    "    # Max top board\n",
    "    choice = 0\n",
    "    top_score = 0\n",
    "    new_scores = []\n",
    "    old_scores = []\n",
    "    for i, board in enumerate(top_boards):\n",
    "        score = 1\n",
    "        old_score = 1\n",
    "        for row in range(0,9):\n",
    "            for col in range(0,9):\n",
    "                score *= ml_predictions[row, col, board[row, col]]\n",
    "                old_score *= original_ml_predictions[row, col, board[row, col]]\n",
    "        new_scores.append(score)\n",
    "        old_scores.append(old_score)\n",
    "        if score > top_score:\n",
    "            top_score = score\n",
    "            choice = i \n",
    "    \n",
    "    return complete_board_list[choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff3f34-2d66-4747-9a32-4c8f661acdeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Finetune SLN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f2399-c627-47fc-b671-cb04e0fbf6c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## For k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401447ef-7bdd-4ea5-b4e8-dd17b717f4a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make train list\n",
    "\n",
    "trained_cnn = SmallLeNet2()\n",
    "trained_cnn.load_state_dict(torch.load('SmallLeNet2_0.957_digit_acc_0.972.pth'))\n",
    "trained_cnn.eval()\n",
    "\n",
    "train_list = []\n",
    "\n",
    "for index in range(0, 7000):\n",
    "    numerical_sudoku = numerical_train_sudokus[index].numpy()\n",
    "    visual_sudoku = visual_train_sudokus[index]\n",
    "    \n",
    "    top_boards = top_k_inference_unique_solution(visual_sudoku, trained_cnn, k=2)\n",
    "    diff = top_boards[0][\"perception\"]-top_boards[1][\"perception\"]\n",
    "    true_indices = np.where(diff!=0)\n",
    "\n",
    "    first_board = [top_boards[0][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    second_board = [top_boards[1][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    correct_board = [numerical_sudoku[true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "\n",
    "    for k in range(0, len(first_board)):\n",
    "        element = [first_board[k], second_board[k], correct_board[k], index, true_indices[0][k], true_indices[1][k]]\n",
    "        train_list.append(element)\n",
    "\n",
    "    if index % 20 == 19:\n",
    "        print(f'Board {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a39ad-d10c-4312-a2ae-54c49a03ddb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make validation list\n",
    "\n",
    "trained_cnn = SmallLeNet2()\n",
    "trained_cnn.load_state_dict(torch.load('SmallLeNet2_0.957_digit_acc_0.972.pth'))\n",
    "trained_cnn.eval()\n",
    "\n",
    "validation_list = []\n",
    "\n",
    "for index in range(0, 1000):\n",
    "    numerical_sudoku = numerical_validation_sudokus[index].numpy()\n",
    "    visual_sudoku = visual_validation_sudokus[index]\n",
    "    \n",
    "    top_boards = top_k_inference_unique_solution(visual_sudoku, trained_cnn, k=2)\n",
    "    diff = top_boards[0][\"perception\"]-top_boards[1][\"perception\"]\n",
    "    true_indices = np.where(diff!=0)\n",
    "\n",
    "    first_board = [top_boards[0][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    second_board = [top_boards[1][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    correct_board = [numerical_sudoku[true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "\n",
    "    board_elements = []\n",
    "    for k in range(0, len(first_board)):\n",
    "        element = [first_board[k], second_board[k], correct_board[k], index, true_indices[0][k], true_indices[1][k]]\n",
    "        board_elements.append(element)\n",
    "    validation_list.append(board_elements)\n",
    "\n",
    "    if index % 20 == 19:\n",
    "        print(f'Board {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad4c87-dde6-432e-a35b-cfe220765889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate board accuracy when using the SLN and symbolic feedback on validation boards,\n",
    "# validation list has been computed earlier with the CNN\n",
    "\n",
    "def print_acc_on_validation_boards(sln, validation_list):\n",
    "    correct = 0\n",
    "    total_digits = 0\n",
    "    loss = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for boards in validation_list:\n",
    "        correct_prob = 1.0\n",
    "        prob1 = 1.0\n",
    "        prob2 = 1.0\n",
    "        for k in range(0, len(boards)):\n",
    "            element = [boards[k][0], boards[k][1], boards[k][2], boards[k][3], boards[k][4], boards[k][5]]\n",
    "            total_digits += 1\n",
    "            \n",
    "            index = element[3]\n",
    "            visual_sudoku = visual_validation_sudokus[index]\n",
    "            \n",
    "            output = sln(visual_sudoku[element[4], element[5]])[0]\n",
    "            pred = torch.nn.functional.softmax(output, dim=0).detach().numpy()\n",
    "            loss += criterion(output.unsqueeze(0), torch.tensor([element[2]]).long())\n",
    "    \n",
    "            correct_prob *= pred[element[2]]\n",
    "            prob1 *= pred[element[0]]\n",
    "            prob2 *= pred[element[1]]\n",
    "            \n",
    "        if np.max([prob1, prob2]) == correct_prob:\n",
    "            correct += 1\n",
    "\n",
    "    print(\"##### Results validation #####\")\n",
    "    print(\"Accuracy: \", correct/len(validation_list))\n",
    "    print(\"Loss: \", loss.item()/len(validation_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc3436-0b12-4f45-999b-c8eb56ab4953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finetune SLN using the train list\n",
    "\n",
    "trained_sln = SmallLeNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(trained_sln.parameters(), lr=0.00001)\n",
    "running_loss = 0\n",
    "\n",
    "for i, element in enumerate(train_list, 0):\n",
    "    index = element[3]\n",
    "    numerical_sudoku = numerical_train_sudokus[index].numpy()\n",
    "    visual_sudoku = visual_train_sudokus[index]\n",
    "    \n",
    "    # Train\n",
    "    optimizer.zero_grad()\n",
    "    output = trained_sln(visual_sudoku[element[4], element[5]])[0]\n",
    "    label = torch.Tensor([element[2]]).long()\n",
    "    loss = criterion(output.unsqueeze(0), label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    if i % 100 == 99:\n",
    "        print(f'Board {i}, Train Loss: {running_loss/100:.4f}')\n",
    "        running_loss = 0.0\n",
    "        print_acc_on_validation_boards(trained_sln, validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed74f6-b97f-4f14-afea-c7a1cc0cf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "\n",
    "# Manual loading\n",
    "sln = SmallLeNet2()\n",
    "sln.load_state_dict(torch.load('SmallLeNet2_0.957_digit_acc_0.972.pth'))\n",
    "print_acc_on_validation_boards(sln, validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c7ebc-fd02-4e6d-80bc-03f214d5769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual saving\n",
    "\n",
    "torch.save(trained_sln.state_dict(), 'SmallLeNet_SLN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f771d9-30bb-4c79-93b1-7ea451d30be8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## For k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070be4cb-0207-4a08-b5a6-1ee1e42ac9ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make train list\n",
    "\n",
    "trained_cnn = LeNet()\n",
    "trained_cnn.load_state_dict(torch.load('LeNet_0.987.pth'))\n",
    "trained_cnn.eval()\n",
    "\n",
    "train_list = []\n",
    "\n",
    "for index in range(0, 7000):\n",
    "    numerical_sudoku = numerical_train_sudokus[index].numpy()\n",
    "    visual_sudoku = visual_train_sudokus[index]\n",
    "    \n",
    "    top_boards = top_k_inference_unique_solution(visual_sudoku, trained_cnn, k=3)\n",
    "    diff = (top_boards[0][\"perception\"]-top_boards[1][\"perception\"]) + (top_boards[0][\"perception\"]-top_boards[2][\"perception\"]) + (top_boards[1][\"perception\"]-top_boards[2][\"perception\"])\n",
    "    true_indices = np.where(diff!=0)\n",
    "\n",
    "    first_board = [top_boards[0][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    second_board = [top_boards[1][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    third_board = [top_boards[2][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    correct_board = [numerical_sudoku[true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "\n",
    "    for k in range(0, len(first_board)):\n",
    "        element = [first_board[k], second_board[k], third_board[k], correct_board[k], index, true_indices[0][k], true_indices[1][k]]\n",
    "        train_list.append(element)\n",
    "\n",
    "    if index % 20 == 19:\n",
    "        print(f'Board {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba83cc4-6da7-4fa3-844e-fbbc8d13bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make validation list\n",
    "\n",
    "trained_cnn = LeNet()\n",
    "trained_cnn.load_state_dict(torch.load('LeNet_0.987.pth'))\n",
    "trained_cnn.eval()\n",
    "\n",
    "validation_list = []\n",
    "\n",
    "for index in range(0, 1000):\n",
    "    numerical_sudoku = numerical_validation_sudokus[index].numpy()\n",
    "    visual_sudoku = visual_validation_sudokus[index]\n",
    "    \n",
    "    top_boards = top_k_inference_unique_solution(visual_sudoku, trained_cnn, k=3)\n",
    "    diff = (top_boards[0][\"perception\"]-top_boards[1][\"perception\"]) + 10*(top_boards[0][\"perception\"]-top_boards[2][\"perception\"]) + 100*(top_boards[1][\"perception\"]-top_boards[2][\"perception\"])\n",
    "    true_indices = np.where(diff!=0)\n",
    "\n",
    "    first_board = [top_boards[0][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    second_board = [top_boards[1][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    third_board = [top_boards[2][\"perception\"][true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "    correct_board = [numerical_sudoku[true_indices[0][i], true_indices[1][i]] for i in range(0, len(true_indices[0]))]\n",
    "\n",
    "    board_elements = []\n",
    "    for k in range(0, len(first_board)):\n",
    "        element = [first_board[k], second_board[k], third_board[k], correct_board[k], index, true_indices[0][k], true_indices[1][k]]\n",
    "        board_elements.append(element)\n",
    "\n",
    "    # Only add to validation list if correct board is among the top-3\n",
    "    for board in top_boards:\n",
    "        if np.array_equal(numerical_sudoku, board[\"perception\"]):\n",
    "            validation_list.append(board_elements)\n",
    "            break\n",
    "\n",
    "    if index % 20 == 19:\n",
    "        print(f'Board {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9a5df-de35-4efd-8f27-5aa921adcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate board accuracy when using the SLN and symbolic feedback on validation boards,\n",
    "# validation list has been computed earlier with the CNN\n",
    "\n",
    "def print_acc_on_validation_boards(sln, validation_list):\n",
    "    correct = 0\n",
    "    total_digits = 0\n",
    "    loss = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for boards in validation_list:\n",
    "        correct_prob = 1.0\n",
    "        prob1 = 1.0\n",
    "        prob2 = 1.0\n",
    "        prob3 = 1.0\n",
    "        for k in range(0, len(boards)):\n",
    "            element = [boards[k][0], boards[k][1], boards[k][2], boards[k][3], boards[k][4], boards[k][5], boards[k][6]]\n",
    "            total_digits += 1\n",
    "            \n",
    "            index = element[4]\n",
    "            visual_sudoku = visual_validation_sudokus[index]\n",
    "            \n",
    "            output = sln(visual_sudoku[element[5], element[6]])[0]\n",
    "            pred = torch.nn.functional.softmax(output, dim=0).detach().numpy()\n",
    "            loss += criterion(output.unsqueeze(0), torch.tensor([element[3]]).long())\n",
    "    \n",
    "            correct_prob *= pred[element[3]]\n",
    "            prob1 *= pred[element[0]]\n",
    "            prob2 *= pred[element[1]]\n",
    "            prob3 *= pred[element[2]]\n",
    "            \n",
    "        if np.max([prob1, prob2, prob3]) == correct_prob:\n",
    "            correct += 1\n",
    "\n",
    "    print(\"##### Results validation #####\")\n",
    "    print(\"Accuracy: \", correct/1000)\n",
    "    print(\"Loss: \", loss.item()/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929a177-9659-4334-b81d-4f2baca67c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finetune SLN using the train list\n",
    "\n",
    "trained_sln = LeNet()\n",
    "trained_sln.load_state_dict(torch.load('LeNet_0.987.pth'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(trained_sln.parameters(), lr=0.00001)\n",
    "running_loss = 0\n",
    "\n",
    "for i, element in enumerate(train_list, 0):\n",
    "    index = element[4]\n",
    "    numerical_sudoku = numerical_train_sudokus[index].numpy()\n",
    "    visual_sudoku = visual_train_sudokus[index]\n",
    "    \n",
    "    # Train\n",
    "    optimizer.zero_grad()\n",
    "    output = trained_sln(visual_sudoku[element[5], element[6]])[0]\n",
    "    label = torch.Tensor([element[3]]).long()\n",
    "    loss = criterion(output.unsqueeze(0), label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    if i % 100 == 99:\n",
    "        print(\"------------------------------\")\n",
    "        print(f'Board {i}, Train Loss: {running_loss/100:.4f}')\n",
    "        running_loss = 0.0\n",
    "        print_acc_on_validation_boards(trained_sln, validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22e662-715d-4b3c-90a4-e33d4a8b6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "\n",
    "# Manual loading\n",
    "sln = LeNet()\n",
    "sln.load_state_dict(torch.load('LeNet_SLN_0.988_finetuned_for_0.987_k=3_digit_acc_0.992.pth'))\n",
    "print_acc_on_validation_boards(sln, validation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3677e-5676-4bfc-8628-f897e4c7fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual saving\n",
    "\n",
    "torch.save(trained_sln.state_dict(), 'LeNet_SLN_digit_acc_0.9.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860805f-c857-4f0b-b6f0-b984211ce5db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c7416-b3a3-4b84-8962-1971b477650f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation\n",
    "\n",
    "# Manual loading\n",
    "trained_cnn = LeNet()\n",
    "trained_cnn.load_state_dict(torch.load('LeNet_0.987.pth'))\n",
    "trained_cnn.eval()\n",
    "trained_sln = SmallLeNet()\n",
    "trained_sln.load_state_dict(torch.load('SmallLeNet_0.960.pth'))\n",
    "trained_sln.eval()\n",
    "\n",
    "total = 0\n",
    "normal_correct = 0\n",
    "feedback_correct = 0\n",
    "four_boards_correct = 0\n",
    "normal_correct_feedback_not = 0\n",
    "feedback_correct_normal_not = 0\n",
    "\n",
    "for i in range(0, 20):\n",
    "    numerical_sudoku = numerical_validation_sudokus[i]\n",
    "    visual_sudoku = visual_validation_sudokus[i]\n",
    "\n",
    "    normal_result = inference_unique_solution(visual_sudoku, trained_cnn)[\"perception\"]\n",
    "    feedback_result = inference_with_feedback_double_cnn(visual_sudoku, trained_cnn, trained_sln, 3)[\"perception\"]\n",
    "    four_boards = top_k_inference_unique_solution(visual_sudoku, trained_cnn, k=3)\n",
    "\n",
    "    normal_correct_bool = False\n",
    "    feedback_correct_bool = False\n",
    "    \n",
    "    if np.array_equal(numerical_sudoku, normal_result):\n",
    "        normal_correct += 1\n",
    "        normal_correct_bool = True\n",
    "    if np.array_equal(numerical_sudoku, feedback_result):\n",
    "        feedback_correct += 1\n",
    "        feedback_correct_bool = True\n",
    "    for board in four_boards:\n",
    "        if np.array_equal(numerical_sudoku, board[\"perception\"]):\n",
    "            four_boards_correct += 1\n",
    "            break\n",
    "\n",
    "    total += 1\n",
    "    if normal_correct_bool and not feedback_correct_bool:\n",
    "        normal_correct_feedback_not += 1\n",
    "        print(\"score: \", normal_correct_feedback_not, feedback_correct_normal_not)\n",
    "    elif feedback_correct_bool and not normal_correct_bool:\n",
    "        feedback_correct_normal_not += 1\n",
    "        print(\"score: \", normal_correct_feedback_not, feedback_correct_normal_not)\n",
    "    print(total, normal_correct/total, feedback_correct/total, four_boards_correct/total)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db895d-49a0-4dba-8347-79245abfc2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "# Manual loading\n",
    "trained_cnn = LeNet()\n",
    "trained_cnn.load_state_dict(torch.load('LeNet_0.987.pth'))\n",
    "trained_cnn.eval()\n",
    "trained_sln = SmallLeNet()\n",
    "trained_sln.load_state_dict(torch.load('SmallLeNet_0.960.pth'))\n",
    "trained_sln.eval()\n",
    "\n",
    "total = 0\n",
    "normal_correct = 0\n",
    "feedback_correct = 0\n",
    "four_boards_correct = 0\n",
    "normal_correct_feedback_not = 0\n",
    "feedback_correct_normal_not = 0\n",
    "\n",
    "for i in range(1000, 2000):\n",
    "    numerical_sudoku = numerical_test_sudokus[i]\n",
    "    visual_sudoku = visual_test_sudokus[i]\n",
    "\n",
    "    normal_result = inference_unique_solution(visual_sudoku, trained_cnn)[\"perception\"]\n",
    "    feedback_result = inference_with_feedback_double_cnn(visual_sudoku, trained_cnn, trained_sln, 3)[\"perception\"]\n",
    "    four_boards = top_k_inference_unique_solution(visual_sudoku, trained_cnn, k=3)\n",
    "\n",
    "    normal_correct_bool = False\n",
    "    feedback_correct_bool = False\n",
    "    \n",
    "    if np.array_equal(numerical_sudoku, normal_result):\n",
    "        normal_correct += 1\n",
    "        normal_correct_bool = True\n",
    "    if np.array_equal(numerical_sudoku, feedback_result):\n",
    "        feedback_correct += 1\n",
    "        feedback_correct_bool = True\n",
    "    for board in four_boards:\n",
    "        if np.array_equal(numerical_sudoku, board[\"perception\"]):\n",
    "            four_boards_correct += 1\n",
    "            break\n",
    "\n",
    "    total += 1\n",
    "    if normal_correct_bool and not feedback_correct_bool:\n",
    "        normal_correct_feedback_not += 1\n",
    "        print(\"score: \", normal_correct_feedback_not, feedback_correct_normal_not)\n",
    "    elif feedback_correct_bool and not normal_correct_bool:\n",
    "        feedback_correct_normal_not += 1\n",
    "        print(\"score: \", normal_correct_feedback_not, feedback_correct_normal_not)\n",
    "    print(total, normal_correct/total, feedback_correct/total, four_boards_correct/total)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d7da1-2926-4f4a-bdcc-65f469dabe6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test accuracy of CNN on digits of the visual sudoku boards\n",
    "\n",
    "# Manual loading\n",
    "#cnn = SmallLeNet()\n",
    "#cnn.load_state_dict(torch.load('SmallLeNet_0.964.pth'))\n",
    "\n",
    "total = 0\n",
    "cnn_correct = 0\n",
    "for i in range(0, 2000):\n",
    "    numerical_sudoku = numerical_test_sudokus[i]\n",
    "    visual_sudoku = visual_test_sudokus[i]\n",
    "\n",
    "    ml_predictions = predict_proba_sudoku(cnn, visual_sudoku)\n",
    "\n",
    "    _, cnn_prediction = torch.max(torch.tensor(ml_predictions).data, -1)\n",
    "    cnn_prediction = cnn_prediction.numpy()\n",
    "    non_zero = (numerical_sudoku != 0).sum().item()\n",
    "    cnn_correct += ((cnn_prediction == numerical_sudoku.numpy())).sum().item()\n",
    "    \n",
    "    total += 81\n",
    "    print(i, cnn_correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
